{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "1DnL1QT3Hk_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeDgHmJWn9xO",
        "outputId": "e6e11eb6-72fb-4b01-bfa4-6e9301957321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Print the PyTorch version to ensure it's installed and functioning correctly.\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a CUDA-enabled GPU is available for computations.\n",
        "# If available, it prints the name of the first CUDA device.\n",
        "if torch.cuda.is_available():\n",
        "    print(\"cuda is available\",torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"cuda is not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVXxj2jroLt9",
        "outputId": "74ffb2a6-cefc-4bf6-9e74-4215dc555a55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Creating tesnsors"
      ],
      "metadata": {
        "id": "bUvCUa4gp5hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty tensor of shape (2, 3).\n",
        "# The values are uninitialized and will contain arbitrary memory content.\n",
        "a=torch.empty(2,3)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJrCWgpcoRrl",
        "outputId": "bb42095a-7433-492d-8ee2-253797036b43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 2.2421e-44, 0.0000e+00],\n",
              "        [7.0079e-39, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data type of the tensor 'a'.\n",
        "# By default, PyTorch creates float32 tensors.\n",
        "type(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvoFFeoGqy-R",
        "outputId": "3fed1279-59a9-4c96-e448-d0d4f7daa09a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of shape (2, 3) filled with zeros.\n",
        "b=torch.zeros(2,3)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S3vNdhIrBpL",
        "outputId": "081ee86e-19a3-4199-d7a3-419c0c4f95e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of shape (2, 3) filled with ones.\n",
        "c=torch.ones(2,3)\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krpa_6tDrIUR",
        "outputId": "a12e450b-96f4-414e-f83c-e9fbfaf4efcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of shape (2, 3) with random values uniformly sampled from [0, 1).\n",
        "d=torch.rand(2,3)\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "770FHMOPrKOe",
        "outputId": "6ad6a0d4-e6be-4c77-c6a4-bc1600835fb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1809, 0.8569, 0.9660],\n",
              "        [0.3295, 0.0416, 0.7860]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed for reproducibility.\n",
        "# This ensures that subsequent random tensor creations will produce the same sequence of numbers.\n",
        "torch.manual_seed(100)\n",
        "e=torch.rand(2,3)\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kfDkvrerNR7",
        "outputId": "d22d24ef-c7d1-4246-ae14-f2bc9de6b025"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1117, 0.8158, 0.2626],\n",
              "        [0.4839, 0.6765, 0.7539]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed again to demonstrate reproducibility.\n",
        "# 'f' will have the same random values as 'e' because the seed is reset.\n",
        "torch.manual_seed(100)\n",
        "f=torch.rand(2,3)\n",
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZymReo5rPvt",
        "outputId": "9703c13f-3ab3-4247-9c59-03653debb3a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1117, 0.8158, 0.2626],\n",
              "        [0.4839, 0.6765, 0.7539]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor directly from a Python list or NumPy array.\n",
        "g=torch.tensor([[1,2,3],[4,5,6]])\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOWs4_1vtKRh",
        "outputId": "f2beee2c-7305-4864-b4fc-cee44408cc60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other ways to create tensors:\n",
        "\n",
        "# Using torch.arange: Creates a 1D tensor with values from 1 to 10 (exclusive) with a step of 2.\n",
        "h=torch.arange(1,10,2)\n",
        "print(h)\n",
        "\n",
        "# Using torch.linspace: Creates a 1D tensor with 5 evenly spaced points between 1 and 10 (inclusive).\n",
        "i=torch.linspace(1,10,steps=5)\n",
        "print(i)\n",
        "\n",
        "# Using torch.eye: Creates a 5x5 identity matrix.\n",
        "j=torch.eye(5)\n",
        "print(j)\n",
        "\n",
        "# Using torch.full: Creates a tensor of shape (2, 3) filled with the specified value (4).\n",
        "k=torch.full((2,3),4)\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ3EGUGMtPv7",
        "outputId": "fb92dc5c-7f0d-405e-bcc4-f7f28407d7ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5, 7, 9])\n",
            "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([[4, 4, 4],\n",
            "        [4, 4, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Shape"
      ],
      "metadata": {
        "id": "tO6Eeihlubjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape (dimensions) of tensor 'j'.\n",
        "# `shape` returns a torch.Size object, which is a tuple-like object.\n",
        "j.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjIOvLZntwfi",
        "outputId": "2b7e8719-1d6e-4503-f372-1bf50dfaac27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty tensor with the same shape as an existing tensor 'j'.\n",
        "# The values are uninitialized.\n",
        "t=torch.empty_like(j)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELYv0o0vufhH",
        "outputId": "827f7c4b-4100-4ab7-f31f-a39bbbdc6b92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.2428e-03, 0.0000e+00, 8.0700e-03, 0.0000e+00, 1.1210e-43],\n",
              "        [0.0000e+00, 8.9683e-44, 0.0000e+00, 8.1105e-03, 0.0000e+00],\n",
              "        [0.0000e+00, 1.5046e-36, 1.7371e-06, 0.0000e+00, 1.0842e-19],\n",
              "        [0.0000e+00, 8.0457e-03, 0.0000e+00, 8.0251e-03, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 1.3593e-43, 0.0000e+00, 8.0472e-03]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor filled with ones, using the same shape as tensor 'j'.\n",
        "q=torch.ones_like(j)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm1ObzUSvd-5",
        "outputId": "235e5dd6-e111-464f-dd13-20a5a3e26dbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values, using the same shape as tensor 'j'.\n",
        "w=torch.rand_like(j)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAVIG4EcvoXv",
        "outputId": "2ad9c3ff-6cc1-4714-a4a7-997ddec84a32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2627, 0.0428, 0.2080, 0.1180, 0.1217],\n",
              "        [0.7356, 0.7118, 0.7876, 0.4183, 0.9014],\n",
              "        [0.9969, 0.7565, 0.2239, 0.3023, 0.1784],\n",
              "        [0.8238, 0.5557, 0.9770, 0.4440, 0.9478],\n",
              "        [0.7445, 0.4892, 0.2426, 0.7003, 0.5277]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor filled with zeros, using the same shape as tensor 'k'.\n",
        "e=torch.zeros_like(k)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmjB_HBZvqU8",
        "outputId": "89b81b63-8ec5-4014-a0ec-6f53b30403c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 4, 4],\n",
              "        [4, 4, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatype"
      ],
      "metadata": {
        "id": "ccFo8FjXwEqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the data type of tensor 'w'.\n",
        "# Common data types include torch.float32, torch.float64, torch.int32, torch.int64, etc.\n",
        "w.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6LHT45fvv4K",
        "outputId": "973fce78-aca7-480a-efcd-94bc3a6a6cb5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and explicitly assign its data type to float32.\n",
        "torch.tensor([[1,2,4,5],[1,2,34,5]],dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YF0fVulwLqj",
        "outputId": "6a66970d-d484-42cf-f414-299084e28bce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  2.,  4.,  5.],\n",
              "        [ 1.,  2., 34.,  5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and explicitly assign its data type to int32.\n",
        "torch.tensor([[1,2,4,5],[1,2,34,5]],dtype=torch.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJdSQqj_whwk",
        "outputId": "92afcd11-a4fe-4ad0-8cf5-4c62695af2c8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  4,  5],\n",
              "        [ 1,  2, 34,  5]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensor 't' to a new tensor with data type int32.\n",
        "# The original tensor 't' remains unchanged.\n",
        "t.to(torch.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syJYyX0MwoXR",
        "outputId": "98a810f8-8061-4119-c340-7944f9465667"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical operatons\n",
        "\n",
        "### 1.Scaler Operations\n"
      ],
      "metadata": {
        "id": "V8Gg-N8-xKXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x4 tensor with random values for demonstrating scalar operations.\n",
        "x=torch.rand(2,4)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqzEN3Y0wynG",
        "outputId": "a32df556-51fb-48bd-c885-fa42473e4a81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2472, 0.7909, 0.4235, 0.0169],\n",
              "        [0.2209, 0.9535, 0.7064, 0.1629]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar addition: Add 1 to every element of tensor x.\n",
        "print(x + 1)\n",
        "\n",
        "# Scalar subtraction: Subtract 1 from every element of tensor x.\n",
        "print(x - 1)\n",
        "\n",
        "# Scalar multiplication: Multiply every element of tensor x by 2.\n",
        "print(x * 2)\n",
        "\n",
        "# Scalar division: Divide every element of tensor x by 2.\n",
        "print(x / 2)\n",
        "\n",
        "# Integer division: Multiply by 100 then integer divide by 2.\n",
        "print((x * 100) // 2)\n",
        "\n",
        "# Modulo: Compute the remainder of each element when divided by 2.\n",
        "print(x % 2)\n",
        "\n",
        "# Power: Raise each element of tensor x to the power of 5.\n",
        "print(x ** 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-edscWbfxeFY",
        "outputId": "29eafe67-f32b-456a-8f86-8e18b6d05edf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2472, 1.7909, 1.4235, 1.0169],\n",
            "        [1.2209, 1.9535, 1.7064, 1.1629]])\n",
            "tensor([[-0.7528, -0.2091, -0.5765, -0.9831],\n",
            "        [-0.7791, -0.0465, -0.2936, -0.8371]])\n",
            "tensor([[0.4944, 1.5818, 0.8470, 0.0338],\n",
            "        [0.4418, 1.9071, 1.4128, 0.3258]])\n",
            "tensor([[0.1236, 0.3954, 0.2117, 0.0084],\n",
            "        [0.1104, 0.4768, 0.3532, 0.0814]])\n",
            "tensor([[12., 39., 21.,  0.],\n",
            "        [11., 47., 35.,  8.]])\n",
            "tensor([[0.2472, 0.7909, 0.4235, 0.0169],\n",
            "        [0.2209, 0.9535, 0.7064, 0.1629]])\n",
            "tensor([[9.2278e-04, 3.0944e-01, 1.3621e-02, 1.3782e-09],\n",
            "        [5.2593e-04, 7.8829e-01, 1.7590e-01, 1.1463e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Elementwies operation"
      ],
      "metadata": {
        "id": "G1XCywqQzAZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two random 2x3 tensors for demonstrating element-wise operations.\n",
        "a=torch.rand(2,3)\n",
        "b=torch.rand(2,3)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImurFP1eyY2W",
        "outputId": "b34c8f44-b27e-453f-b306-1159eac1fe94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8902, 0.5163, 0.0359],\n",
            "        [0.6476, 0.3430, 0.3182]])\n",
            "tensor([[0.5261, 0.0447, 0.5123],\n",
            "        [0.9051, 0.5989, 0.4450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Element-wise addition of tensors a and b.\n",
        "print(\"a + b:\\n\", a + b)\n",
        "\n",
        "# Element-wise subtraction of tensors a and b.\n",
        "print(\"a - b:\\n\", a - b)\n",
        "\n",
        "# Element-wise multiplication of tensors a and b.\n",
        "print(\"a * b:\\n\", a * b)\n",
        "\n",
        "# Element-wise division of tensors a and b.\n",
        "print(\"a / b:\\n\", a / b)\n",
        "\n",
        "# Element-wise power: Raise elements of a to the power of corresponding elements in b.\n",
        "print(\"a ** b:\\n\", a ** b)\n",
        "\n",
        "# Element-wise maximum: Returns a new tensor with the maximum of each pair of elements from a and b.\n",
        "print(\"max(a, b):\\n\", torch.max(a, b))\n",
        "\n",
        "# Element-wise minimum: Returns a new tensor with the minimum of each pair of elements from a and b.\n",
        "print(\"min(a, b):\\n\", torch.min(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354W_90WzXJl",
        "outputId": "be4235ab-3312-4b35-b80e-1b8eebfee741"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b:\n",
            " tensor([[1.4163, 0.5609, 0.5482],\n",
            "        [1.5527, 0.9419, 0.7632]])\n",
            "a - b:\n",
            " tensor([[ 0.3641,  0.4716, -0.4765],\n",
            "        [-0.2574, -0.2558, -0.1268]])\n",
            "a * b:\n",
            " tensor([[0.4683, 0.0231, 0.0184],\n",
            "        [0.5862, 0.2054, 0.1416]])\n",
            "a / b:\n",
            " tensor([[ 1.6921, 11.5604,  0.0700],\n",
            "        [ 0.7156,  0.5728,  0.7151]])\n",
            "a ** b:\n",
            " tensor([[0.9406, 0.9709, 0.1818],\n",
            "        [0.6749, 0.5269, 0.6008]])\n",
            "max(a, b):\n",
            " tensor([[0.8902, 0.5163, 0.5123],\n",
            "        [0.9051, 0.5989, 0.4450]])\n",
            "min(a, b):\n",
            " tensor([[0.5261, 0.0447, 0.0359],\n",
            "        [0.6476, 0.3430, 0.3182]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"abs(a):\\n\", torch.abs(a))        # absolute value of each element\n",
        "print(\"ceil(a):\\n\", torch.ceil(a))      # round up each element to the smallest integer greater than or equal to it\n",
        "print(\"floor(a):\\n\", torch.floor(a))    # round down each element to the largest integer less than or equal to it\n",
        "print(\"round(a):\\n\", torch.round(a))    # round each element to the nearest integer\n",
        "\n",
        "print(\"sqrt(a.abs()):\\n\", torch.sqrt(torch.abs(a)))  # square root of the absolute value of each element\n",
        "print(\"exp(a):\\n\", torch.exp(a))        # exponential of each element (e^x)\n",
        "print(\"log(abs(a)+1):\\n\", torch.log(torch.abs(a) + 1))  # natural logarithm of (absolute value of each element + 1)\n",
        "\n",
        "print(\"sin(a):\\n\", torch.sin(a))        # sine of each element\n",
        "print(\"cos(a):\\n\", torch.cos(a))        # cosine of each element\n",
        "print(\"tan(a):\\n\", torch.tan(a))        # tangent of each element\n",
        "\n",
        "print(\"clamp(a, -1, 1):\\n\", torch.clamp(a, 2, 3))  # element-wise clipping: values below 2 become 2, values above 3 become 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pljGekAxzhEq",
        "outputId": "0c3fc338-4d76-4c98-ea4c-fafb516ac402"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abs(a):\n",
            " tensor([[0.8902, 0.5163, 0.0359],\n",
            "        [0.6476, 0.3430, 0.3182]])\n",
            "ceil(a):\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "floor(a):\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "round(a):\n",
            " tensor([[1., 1., 0.],\n",
            "        [1., 0., 0.]])\n",
            "sqrt(a.abs()):\n",
            " tensor([[0.9435, 0.7185, 0.1894],\n",
            "        [0.8048, 0.5857, 0.5641]])\n",
            "exp(a):\n",
            " tensor([[2.4356, 1.6758, 1.0365],\n",
            "        [1.9110, 1.4092, 1.3747]])\n",
            "log(abs(a)+1):\n",
            " tensor([[0.6367, 0.4163, 0.0353],\n",
            "        [0.4993, 0.2949, 0.2763]])\n",
            "sin(a):\n",
            " tensor([[0.7772, 0.4936, 0.0359],\n",
            "        [0.6033, 0.3363, 0.3129]])\n",
            "cos(a):\n",
            " tensor([[0.6293, 0.8697, 0.9994],\n",
            "        [0.7975, 0.9417, 0.9498]])\n",
            "tan(a):\n",
            " tensor([[1.2351, 0.5676, 0.0359],\n",
            "        [0.7565, 0.3571, 0.3294]])\n",
            "clamp(a, -1, 1):\n",
            " tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Reducation operations"
      ],
      "metadata": {
        "id": "LGywQkPP0sXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a random integer tensor of shape (2,3) with values between 0 and 9, and cast to float32.\n",
        "e = torch.randint(low=0, high=10, size=(2,3),dtype=torch.float32)\n",
        "print(\"e:\\n\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd7MW3zZ0igN",
        "outputId": "c829f046-7044-4672-b3bd-8397e0d00602"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e:\n",
            " tensor([[9., 2., 6.],\n",
            "        [7., 7., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the sum of all elements in tensor 'e'.\n",
        "print(\"\\nsum:\\n\", torch.sum(e))\n",
        "# Calculate the sum of elements along dimension 0 (columns).\n",
        "print(\"\\nsum(dim=0):\\n\", torch.sum(e, dim=0))\n",
        "# Calculate the sum of elements along dimension 1 (rows).\n",
        "print(\"\\nsum(dim=1):\\n\", torch.sum(e, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-6hbpqi1EQw",
        "outputId": "b2fa39f1-c662-4de8-f427-55ddd23586b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sum:\n",
            " tensor(39.)\n",
            "\n",
            "sum(dim=0):\n",
            " tensor([16.,  9., 14.])\n",
            "\n",
            "sum(dim=1):\n",
            " tensor([17., 22.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- MEAN -----\n",
        "# Calculate the mean of all elements in tensor 'e'. Must cast to float for mean.\n",
        "print(\"\\nmean:\\n\", torch.mean(e.float()))\n",
        "\n",
        "\n",
        "# ----- PRODUCT -----\n",
        "# Calculate the product of all elements in tensor 'e'.\n",
        "print(\"\\nproduct:\\n\", torch.prod(e))\n",
        "\n",
        "\n",
        "# ----- MAX -----\n",
        "# Find the maximum value in tensor 'e'.\n",
        "print(\"\\nmax:\\n\", torch.max(e))\n",
        "\n",
        "\n",
        "# ----- MIN -----\n",
        "# Find the minimum value in tensor 'e'.\n",
        "print(\"\\nmin:\\n\", torch.min(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6_LjJiW1Q5_",
        "outputId": "7ca1c3c4-ff19-4d1b-b2e4-8e95d2737aa5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "mean:\n",
            " tensor(6.5000)\n",
            "\n",
            "product:\n",
            " tensor(42336.)\n",
            "\n",
            "max:\n",
            " tensor(9.)\n",
            "\n",
            "min:\n",
            " tensor(2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ----- ARGMAX -----\n",
        "# Find the index of the maximum value in the flattened tensor 'e'.\n",
        "print(\"\\nargmax (flattened index):\\n\", torch.argmax(e))\n",
        "\n",
        "\n",
        "# ----- ARGMIN -----\n",
        "# Find the index of the minimum value in the flattened tensor 'e'.\n",
        "print(\"\\nargmin (flattened index):\\n\", torch.argmin(e))\n",
        "\n",
        "\n",
        "# ----- SUM ALONG DIMENSIONS -----\n",
        "# Calculate the sum of elements along dimension 0 (columns).\n",
        "print(\"\\nsum(dim=0):\\n\", torch.sum(e, dim=0))\n",
        "# Calculate the sum of elements along dimension 1 (rows).\n",
        "print(\"sum(dim=1):\\n\", torch.sum(e, dim=1))\n",
        "\n",
        "\n",
        "# ----- MEAN ALONG DIMENSIONS -----\n",
        "# Calculate the mean of elements along dimension 0 (columns), cast to float.\n",
        "print(\"\\nmean(dim=0):\\n\", torch.mean(e.float(), dim=0))\n",
        "# Calculate the mean of elements along dimension 1 (rows), cast to float.\n",
        "print(\"mean(dim=1):\\n\", torch.mean(e.float(), dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JQDHs0D1oUc",
        "outputId": "0356b1bd-9516-4c4d-f17b-7560e945f048"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "argmax (flattened index):\n",
            " tensor(0)\n",
            "\n",
            "argmin (flattened index):\n",
            " tensor(1)\n",
            "\n",
            "sum(dim=0):\n",
            " tensor([16.,  9., 14.])\n",
            "sum(dim=1):\n",
            " tensor([17., 22.])\n",
            "\n",
            "mean(dim=0):\n",
            " tensor([8.0000, 4.5000, 7.0000])\n",
            "mean(dim=1):\n",
            " tensor([5.6667, 7.3333])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ----- STANDARD DEVIATION -----\n",
        "# Calculate the standard deviation of all elements in tensor 'e'.\n",
        "print(\"\\nstd:\\n\", torch.std(e.float()))\n",
        "\n",
        "\n",
        "# ----- VARIANCE -----\n",
        "# Calculate the variance of all elements in tensor 'e'.\n",
        "print(\"\\nvar:\\n\", torch.var(e.float()))\n",
        "\n",
        "\n",
        "# ----- ANY / ALL (logical reductions) -----\n",
        "# Check if any element in 'e' is greater than 5.\n",
        "print(\"\\nany > 5:\\n\", torch.any(e > 5))\n",
        "# Check if all elements in 'e' are greater than 0.\n",
        "print(\"all > 0:\\n\", torch.all(e > 0))\n",
        "\n",
        "\n",
        "# ----- L1 & L2 NORM -----\n",
        "# Calculate the L2 (Euclidean) norm of tensor 'e'.\n",
        "print(\"\\nL2 norm:\\n\", torch.norm(e.float()))\n",
        "# Calculate the L1 (Manhattan) norm of tensor 'e'.\n",
        "print(\"L1 norm:\\n\", torch.norm(e.float(), p=1))\n",
        "\n",
        "\n",
        "# ----- MEDIAN -----\n",
        "# Calculate the median of all elements in tensor 'e'.\n",
        "print(\"\\nmedian:\\n\", torch.median(e.float()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSCw17y_1qux",
        "outputId": "aad3b941-5e7e-43bc-cb09-5531807566a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "std:\n",
            " tensor(2.4290)\n",
            "\n",
            "var:\n",
            " tensor(5.9000)\n",
            "\n",
            "any > 5:\n",
            " tensor(True)\n",
            "all > 0:\n",
            " tensor(True)\n",
            "\n",
            "L2 norm:\n",
            " tensor(16.8226)\n",
            "L1 norm:\n",
            " tensor(39.)\n",
            "\n",
            "median:\n",
            " tensor(7.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.Metrix Operation"
      ],
      "metadata": {
        "id": "LrwjJn3L3xQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randint(0, 10, (3, 3)).float() # Create a 3x3 matrix with random integers (0-9) as floats.\n",
        "B = torch.randint(0, 10, (3, 3)).float() # Create another 3x3 matrix with random integers (0-9) as floats.\n",
        "\n",
        "print(\"A:\\n\", A)\n",
        "print(\"B:\\n\", B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVUlPveN1rYi",
        "outputId": "80613540-abe7-467f-8d8c-2f570386c288"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:\n",
            " tensor([[3., 6., 1.],\n",
            "        [5., 5., 0.],\n",
            "        [4., 3., 8.]])\n",
            "B:\n",
            " tensor([[8., 3., 3.],\n",
            "        [5., 0., 6.],\n",
            "        [4., 0., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----- MATRIX ADDITION -----\n",
        "# Element-wise addition of matrices A and B.\n",
        "print(\"\\nA + B:\\n\", A + B)\n",
        "\n",
        "\n",
        "# ----- MATRIX SUBTRACTION -----\n",
        "# Element-wise subtraction of matrices A and B.\n",
        "print(\"\\nA - B:\\n\", A - B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-P8KYrA3YqN",
        "outputId": "4f5adcd3-e00c-4134-c883-5c1bc531cc61"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A + B:\n",
            " tensor([[11.,  9.,  4.],\n",
            "        [10.,  5.,  6.],\n",
            "        [ 8.,  3., 16.]])\n",
            "\n",
            "A - B:\n",
            " tensor([[-5.,  3., -2.],\n",
            "        [ 0.,  5., -6.],\n",
            "        [ 0.,  3.,  0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----- MATRIX MULTIPLICATION (element-wise) -----\n",
        "# Performs element-wise multiplication (Hadamard product).\n",
        "print(\"\\nA * B (element-wise):\\n\", A * B)\n",
        "\n",
        "\n",
        "# ----- MATRIX MULTIPLICATION (true matmul) -----\n",
        "# Performs true matrix multiplication (dot product of rows and columns).\n",
        "print(\"\\nA @ B (matrix multiply):\\n\", A @ B)\n",
        "\n",
        "\n",
        "# ----- MATRIX MULTIPLY using torch.matmul -----\n",
        "# Another way to perform true matrix multiplication.\n",
        "print(\"\\ntorch.matmul(A, B):\\n\", torch.matmul(A, B))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx913kET3amS",
        "outputId": "af2fab1f-cd0a-4e12-da8f-486b4d8bd0dd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A * B (element-wise):\n",
            " tensor([[24., 18.,  3.],\n",
            "        [25.,  0.,  0.],\n",
            "        [16.,  0., 64.]])\n",
            "\n",
            "A @ B (matrix multiply):\n",
            " tensor([[58.,  9., 53.],\n",
            "        [65., 15., 45.],\n",
            "        [79., 12., 94.]])\n",
            "\n",
            "torch.matmul(A, B):\n",
            " tensor([[58.,  9., 53.],\n",
            "        [65., 15., 45.],\n",
            "        [79., 12., 94.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- DOT PRODUCT (vectors only) -----\n",
        "v1 = torch.tensor([1., 2., 3.]) # Create a 1D tensor (vector).\n",
        "v2 = torch.tensor([4., 5., 6.]) # Create another 1D tensor (vector).\n",
        "print(\"\\ndot product v1·v2:\\n\", torch.dot(v1, v2))\n",
        "\n",
        "\n",
        "# ----- MATRIX TRANSPOSE -----\n",
        "# Transposes matrix A (swaps rows and columns).\n",
        "print(\"\\nA transpose (A.T):\\n\", A.T)\n",
        "\n",
        "\n",
        "# ----- MATRIX INVERSE -----\n",
        "# Computes the inverse of matrix A. Requires A to be square and invertible.\n",
        "print(\"\\nInverse of A:\\n\", torch.inverse(A))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du-8HXWg3ckc",
        "outputId": "54e96f6e-b348-4341-d99e-2b7866831ee4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dot product v1·v2:\n",
            " tensor(32.)\n",
            "\n",
            "A transpose (A.T):\n",
            " tensor([[3., 5., 4.],\n",
            "        [6., 5., 3.],\n",
            "        [1., 0., 8.]])\n",
            "\n",
            "Inverse of A:\n",
            " tensor([[-0.3200,  0.3600,  0.0400],\n",
            "        [ 0.3200, -0.1600, -0.0400],\n",
            "        [ 0.0400, -0.1200,  0.1200]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----- MATRIX DETERMINANT -----\n",
        "# Computes the determinant of matrix A.\n",
        "print(\"\\ndet(A):\\n\", torch.det(A))\n",
        "\n",
        "\n",
        "# ----- MATRIX TRACE (sum of diagonal) -----\n",
        "# Computes the trace of matrix A, which is the sum of its diagonal elements.\n",
        "print(\"\\ntrace(A):\\n\", torch.trace(A))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIE-XNKI3eWW",
        "outputId": "cf3c0d97-950d-482b-cc9a-0731c606afa8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "det(A):\n",
            " tensor(-125.0000)\n",
            "\n",
            "trace(A):\n",
            " tensor(16.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----- MATRIX RANK -----\n",
        "# Computes the rank of matrix A, which is the number of linearly independent rows or columns.\n",
        "print(\"\\nrank(A):\\n\", torch.linalg.matrix_rank(A))\n",
        "\n",
        "\n",
        "# ----- MATRIX EIGENVALUES / EIGENVECTORS -----\n",
        "# Computes the eigenvalues and eigenvectors of matrix A.\n",
        "e_vals, e_vecs = torch.linalg.eig(A)\n",
        "print(\"\\neigenvalues:\\n\", e_vals)\n",
        "print(\"eigenvectors:\\n\", e_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccNaEmVa3gAm",
        "outputId": "388675fa-86f9-4be3-b860-511fc0dc8cd7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "rank(A):\n",
            " tensor(3)\n",
            "\n",
            "eigenvalues:\n",
            " tensor([-1.6753+0.j, 10.7064+0.j,  6.9689+0.j])\n",
            "eigenvectors:\n",
            " tensor([[ 0.7921+0.j, -0.3588+0.j, -0.0863+0.j],\n",
            "        [-0.5933+0.j, -0.3144+0.j, -0.2190+0.j],\n",
            "        [-0.1435+0.j, -0.8789+0.j,  0.9719+0.j]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----- MATRIX SVD (Singular Value Decomposition) -----\n",
        "# Computes the Singular Value Decomposition of matrix A: A = U * diag(S) * Vh.\n",
        "# U and Vh are unitary matrices, and S is a vector of singular values.\n",
        "U, S, Vh = torch.linalg.svd(A)\n",
        "print(\"\\nSVD:\")\n",
        "print(\"U:\\n\", U)\n",
        "print(\"S:\\n\", S)\n",
        "print(\"Vh:\\n\", Vh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAvv-eFb3hTy",
        "outputId": "cebb4053-bc17-48d5-cbf9-58fc0262a13e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVD:\n",
            "U:\n",
            " tensor([[-0.5097, -0.4325, -0.7437],\n",
            "        [-0.5094, -0.5449,  0.6660],\n",
            "        [-0.6933,  0.7184,  0.0574]])\n",
            "S:\n",
            " tensor([11.9439,  6.2909,  1.6636])\n",
            "Vh:\n",
            " tensor([[-0.5735, -0.6435, -0.5070],\n",
            "        [-0.1825, -0.5030,  0.8448],\n",
            "        [ 0.7986, -0.5770, -0.1710]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Comparision Operations"
      ],
      "metadata": {
        "id": "7KJspLwr33gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(0, 10, (3, 3)) # Create a 3x3 tensor with random integers (0-9).\n",
        "y = torch.randint(0, 10, (3, 3)) # Create another 3x3 tensor with random integers (0-9).\n",
        "\n",
        "print(\"x:\\n\", x)\n",
        "print(\"y:\\n\", y)\n",
        "\n",
        "# ----- ELEMENT-WISE COMPARISONS -----\n",
        "print(\"\\nx == y:\\n\", x == y)      # Check if elements are equal.\n",
        "print(\"x != y:\\n\", x != y)        # Check if elements are not equal.\n",
        "print(\"x > y:\\n\", x > y)          # Check if elements of x are greater than y.\n",
        "print(\"x >= y:\\n\", x >= y)        # Check if elements of x are greater than or equal to y.\n",
        "print(\"x < y:\\n\", x < y)          # Check if elements of x are less than y.\n",
        "print(\"x <= y:\\n\", x <= y)        # Check if elements of x are less than or equal to y.\n",
        "\n",
        "# ----- ANY / ALL LOGICAL REDUCTIONS -----\n",
        "print(\"\\nany(x > y):\\n\", torch.any(x > y))    # Check if any element of x is greater than y.\n",
        "print(\"all(x > y):\\n\", torch.all(x > y))     # Check if all elements of x are greater than y."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUr29Rk03j1x",
        "outputId": "c61e9a4e-f1db-41e8-edbe-690adb1abc01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            " tensor([[4, 7, 2],\n",
            "        [3, 8, 5],\n",
            "        [6, 2, 9]])\n",
            "y:\n",
            " tensor([[5, 0, 4],\n",
            "        [2, 7, 1],\n",
            "        [1, 5, 4]])\n",
            "\n",
            "x == y:\n",
            " tensor([[False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "x != y:\n",
            " tensor([[True, True, True],\n",
            "        [True, True, True],\n",
            "        [True, True, True]])\n",
            "x > y:\n",
            " tensor([[False,  True, False],\n",
            "        [ True,  True,  True],\n",
            "        [ True, False,  True]])\n",
            "x >= y:\n",
            " tensor([[False,  True, False],\n",
            "        [ True,  True,  True],\n",
            "        [ True, False,  True]])\n",
            "x < y:\n",
            " tensor([[ True, False,  True],\n",
            "        [False, False, False],\n",
            "        [False,  True, False]])\n",
            "x <= y:\n",
            " tensor([[ True, False,  True],\n",
            "        [False, False, False],\n",
            "        [False,  True, False]])\n",
            "\n",
            "any(x > y):\n",
            " tensor(True)\n",
            "all(x > y):\n",
            " tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.Special Functions"
      ],
      "metadata": {
        "id": "Ibl6sXWP4IhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a tensor with random values.\n",
        "x = torch.randn(3, 3)\n",
        "print(\"x:\\n\", x)\n",
        "# Sigmoid function: squashes values between 0 and 1.\n",
        "print(\"\\nsigmoid(x):\\n\", torch.sigmoid(x))\n",
        "\n",
        "# Natural logarithm (avoid log(0) by adding a small epsilon).\n",
        "print(\"\\nlog(abs(x)+1e-6):\\n\", torch.log(torch.abs(x) + 1e-6))\n",
        "\n",
        "# Exponential function: e^x.\n",
        "print(\"\\nexp(x):\\n\", torch.exp(x))\n",
        "\n",
        "# Tanh function: squashes values between -1 and 1.\n",
        "print(\"\\ntanh(x):\\n\", torch.tanh(x))\n",
        "\n",
        "# ReLU (Rectified Linear Unit) function: max(0, x).\n",
        "print(\"\\nReLU(x):\\n\", torch.relu(x))\n",
        "\n",
        "# Softplus function: log(1 + exp(x)). A smooth approximation to ReLU.\n",
        "print(\"\\nsoftplus(x):\\n\", F.softplus(x))\n",
        "\n",
        "# GELU (Gaussian Error Linear Unit) function: an activation function commonly used in transformers.\n",
        "print(\"\\nGELU(x):\\n\", F.gelu(x))\n",
        "\n",
        "# Square root (use absolute value to avoid NaN for negative inputs).\n",
        "print(\"\\nsqrt(abs(x)):\\n\", torch.sqrt(torch.abs(x)))\n",
        "\n",
        "# Natural logarithm (base e, use abs to avoid NaN for negative inputs).\n",
        "print(\"\\nlog(abs(x)):\\n\", torch.log(torch.abs(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mm0r7Hp4Fb0",
        "outputId": "130df21c-9cee-4682-ee34-d9f70756f344"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            " tensor([[-0.8216,  0.6133, -0.3497],\n",
            "        [ 0.4890, -0.6925,  0.5929],\n",
            "        [-0.0814,  0.1575, -0.3423]])\n",
            "\n",
            "sigmoid(x):\n",
            " tensor([[0.3054, 0.6487, 0.4135],\n",
            "        [0.6199, 0.3335, 0.6440],\n",
            "        [0.4797, 0.5393, 0.4152]])\n",
            "\n",
            "log(abs(x)+1e-6):\n",
            " tensor([[-0.1965, -0.4890, -1.0507],\n",
            "        [-0.7154, -0.3674, -0.5227],\n",
            "        [-2.5083, -1.8484, -1.0719]])\n",
            "\n",
            "exp(x):\n",
            " tensor([[0.4397, 1.8464, 0.7049],\n",
            "        [1.6307, 0.5003, 1.8092],\n",
            "        [0.9218, 1.1706, 0.7101]])\n",
            "\n",
            "tanh(x):\n",
            " tensor([[-0.6759,  0.5464, -0.3361],\n",
            "        [ 0.4534, -0.5996,  0.5320],\n",
            "        [-0.0812,  0.1562, -0.3296]])\n",
            "\n",
            "ReLU(x):\n",
            " tensor([[0.0000, 0.6133, 0.0000],\n",
            "        [0.4890, 0.0000, 0.5929],\n",
            "        [0.0000, 0.1575, 0.0000]])\n",
            "\n",
            "softplus(x):\n",
            " tensor([[0.3645, 1.0461, 0.5335],\n",
            "        [0.9672, 0.4057, 1.0329],\n",
            "        [0.6533, 0.7750, 0.5366]])\n",
            "\n",
            "GELU(x):\n",
            " tensor([[-0.1690,  0.4478, -0.1270],\n",
            "        [ 0.3362, -0.1692,  0.4289],\n",
            "        [-0.0381,  0.0886, -0.1253]])\n",
            "\n",
            "sqrt(abs(x)):\n",
            " tensor([[0.9064, 0.7831, 0.5914],\n",
            "        [0.6993, 0.8322, 0.7700],\n",
            "        [0.2853, 0.3969, 0.5851]])\n",
            "\n",
            "log(abs(x)):\n",
            " tensor([[-0.1965, -0.4890, -1.0507],\n",
            "        [-0.7154, -0.3674, -0.5227],\n",
            "        [-2.5084, -1.8484, -1.0719]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inplace operation"
      ],
      "metadata": {
        "id": "RPWm1-so5TyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor.\n",
        "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "print(\"Original x:\\n\", x)\n",
        "\n",
        "# ----- INPLACE ADDITION -----\n",
        "# Adds 1 to every element of x, modifying x directly.\n",
        "x.add_(1)\n",
        "print(\"\\nx after x.add_(1):\\n\", x)\n",
        "\n",
        "# ----- INPLACE SUBTRACTION -----\n",
        "# Subtracts 2 from every element of x, modifying x directly.\n",
        "x.sub_(2)\n",
        "print(\"\\nx after x.sub_(2):\\n\", x)\n",
        "\n",
        "# ----- INPLACE MULTIPLICATION -----\n",
        "# Multiplies every element of x by 3, modifying x directly.\n",
        "x.mul_(3)\n",
        "print(\"\\nx after x.mul_(3):\\n\", x)\n",
        "\n",
        "# ----- INPLACE DIVISION -----\n",
        "# Divides every element of x by 2, modifying x directly.\n",
        "x.div_(2)\n",
        "print(\"\\nx after x.div_(2):\\n\", x)\n",
        "\n",
        "# ----- INPLACE RELU -----\n",
        "# Create a new tensor for ReLU demonstration.\n",
        "x = torch.tensor([-1.0, 0.0, 2.0, -3.0])\n",
        "print(\"\\nNew x for ReLU:\\n\", x)\n",
        "# Applies ReLU function inplace: negative values become 0.\n",
        "x.relu_()\n",
        "print(\"\\nx after x.relu_():\\n\", x)\n",
        "\n",
        "# ----- INPLACE CLAMP -----\n",
        "# Clamps values of x inplace between 0 and 2.\n",
        "x.clamp_(min=0, max=2)\n",
        "print(\"\\nx after x.clamp_(0, 2):\\n\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYSHogiL4gaZ",
        "outputId": "881ce0e3-60ef-4787-fb53-441bdb37e0f8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x:\n",
            " tensor([1., 2., 3., 4.])\n",
            "\n",
            "x after x.add_(1):\n",
            " tensor([2., 3., 4., 5.])\n",
            "\n",
            "x after x.sub_(2):\n",
            " tensor([0., 1., 2., 3.])\n",
            "\n",
            "x after x.mul_(3):\n",
            " tensor([0., 3., 6., 9.])\n",
            "\n",
            "x after x.div_(2):\n",
            " tensor([0.0000, 1.5000, 3.0000, 4.5000])\n",
            "\n",
            "New x for ReLU:\n",
            " tensor([-1.,  0.,  2., -3.])\n",
            "\n",
            "x after x.relu_():\n",
            " tensor([0., 0., 2., 0.])\n",
            "\n",
            "x after x.clamp_(0, 2):\n",
            " tensor([0., 0., 2., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy tensor"
      ],
      "metadata": {
        "id": "xgw7ZncL6KC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(\"Original x:\\n\", x)\n",
        "\n",
        "# ----- 1. Using clone() -----\n",
        "# Creates a new tensor with the same data as x, but it is a deep copy and does not share memory with x.\n",
        "y = x.clone()\n",
        "print(\"\\ny (clone of x):\\n\", y)\n",
        "\n",
        "# Modify y to show it's independent\n",
        "y.add_(10) # Modifying y will not affect x.\n",
        "print(\"Modified y:\\n\", y)\n",
        "print(\"x remains unchanged:\\n\", x)\n",
        "\n",
        "# ----- 2. Using detach().clone() (common with autograd) -----\n",
        "# `detach()` removes the tensor from the computation graph, and then `clone()` creates a new copy.\n",
        "z = x.detach().clone()\n",
        "print(\"\\nz (detached clone of x):\\n\", z)\n",
        "\n",
        "# ----- 3. Using .copy_() to copy into an existing tensor -----\n",
        "w = torch.zeros(3) # Create a target tensor.\n",
        "w.copy_(x) # Copies the data from x into w inplace.\n",
        "print(\"\\nw after copy_ from x:\\n\", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfZ70xvp57Gn",
        "outputId": "776e1648-25e6-4a90-bc83-e7a317015077"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "y (clone of x):\n",
            " tensor([1., 2., 3.])\n",
            "Modified y:\n",
            " tensor([11., 12., 13.])\n",
            "x remains unchanged:\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "z (detached clone of x):\n",
            " tensor([1., 2., 3.])\n",
            "\n",
            "w after copy_ from x:\n",
            " tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the memory address (ID) of tensor 'x'.\n",
        "# This helps confirm if tensors share the same memory location.\n",
        "id(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjE3Z-Mf6SqX",
        "outputId": "e820bf44-71c4-4a73-a927-606f6b99e8b9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137346908995984"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the memory address (ID) of tensor 'y'.\n",
        "# This should be different from id(x), confirming it's a separate copy.\n",
        "id(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFkZLIL66vvD",
        "outputId": "a180854c-2fd7-4585-b8ce-3ec3803f5925"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137351342230496"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors on GPU\n"
      ],
      "metadata": {
        "id": "RPhUWwGi7rVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a CUDA-enabled GPU is available on the system.\n",
        "# Returns True if CUDA is available, False otherwise.\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm1Z0H_I6xpL",
        "outputId": "ee5a33e7-70be-436c-ee65-c1696d1600c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device to use for tensor operations.\n",
        "# If CUDA is available, 'cuda' device is chosen; otherwise, 'cpu' is used.\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7u18_2PX71d1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new tensor directly on the GPU device.\n",
        "torch.rand((2,3),device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLcEigpL7-Zt",
        "outputId": "b49e0013-8a50-4992-ebcd-af1898fca6fc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3563, 0.0303, 0.7088],\n",
              "        [0.2009, 0.0224, 0.9896]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor on the CPU (default device).\n",
        "a=torch.rand((2,3))"
      ],
      "metadata": {
        "id": "3Ugyk_rb8Pgi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move an existing tensor 'a' from CPU to the specified 'device' (GPU if available).\n",
        "# This operation returns a new tensor on the target device.\n",
        "a.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhXUSmIb8kMo",
        "outputId": "5039386b-04ce-47e1-cc0d-a4cc7f3daa79"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7340, 0.8497, 0.9112],\n",
              "        [0.4847, 0.9436, 0.3904]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Size of the matrices for performance comparison.\n",
        "size = 10000  # Adjust if memory is limited.\n",
        "\n",
        "# Create matrices on CPU.\n",
        "A_cpu = torch.rand(size, size)\n",
        "B_cpu = torch.rand(size, size)\n",
        "\n",
        "# --- MATRIX MULTIPLICATION ON CPU --- (measures time for CPU computation)\n",
        "start_cpu = time.time()\n",
        "C_cpu = torch.matmul(A_cpu, B_cpu)\n",
        "end_cpu = time.time()\n",
        "print(f\"CPU: Matrix multiplication of size {size}x{size} took {end_cpu - start_cpu:.4f} seconds.\")\n",
        "\n",
        "# --- MATRIX MULTIPLICATION ON GPU (if available) --- (measures time for GPU computation)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    A_gpu = A_cpu.to(device) # Move matrices to GPU.\n",
        "    B_gpu = B_cpu.to(device)\n",
        "\n",
        "    # Warm-up GPU: Perform a dummy operation to initialize GPU resources and get more accurate timing.\n",
        "    _ = torch.matmul(A_gpu, B_gpu)\n",
        "\n",
        "    torch.cuda.synchronize()  # Ensure all previous GPU operations have completed before starting timer.\n",
        "    start_gpu = time.time()\n",
        "    C_gpu = torch.matmul(A_gpu, B_gpu) # Perform matrix multiplication on GPU.\n",
        "    torch.cuda.synchronize()  # Wait for GPU to finish its computation before ending timer.\n",
        "    end_gpu = time.time()\n",
        "    print(f\"GPU: Matrix multiplication of size {size}x{size} took {end_gpu - start_gpu:.4f} seconds.\")\n",
        "else:\n",
        "    print(\"GPU not available on this system.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfsrdEr68mnh",
        "outputId": "47dcee1c-8bb1-40f8-bfc1-a42cf829d227"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Matrix multiplication of size 10000x10000 took 29.5272 seconds.\n",
            "GPU: Matrix multiplication of size 10000x10000 took 0.4720 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape tesnors\n"
      ],
      "metadata": {
        "id": "rX0xquzQ-bfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor of shape (2, 3, 4) with values from 0 to 23.\n",
        "x = torch.arange(24).reshape(2, 3, 4)\n",
        "print(\"Original x:\\n\", x)\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "# ----- Reshape to (3, 8) -----\n",
        "# Changes the tensor's shape to 3 rows and 8 columns. The total number of elements must remain the same.\n",
        "y = x.reshape(3, 8)\n",
        "print(\"\\nReshaped to (3, 8):\\n\", y)\n",
        "print(\"Shape:\", y.shape)\n",
        "\n",
        "# ----- Reshape using view (same as reshape for contiguous tensors) -----\n",
        "# `view` can only operate on tensors that are contiguous in memory. `reshape` can handle non-contiguous tensors.\n",
        "z = x.view(4, 6)\n",
        "print(\"\\nView to (4, 6):\\n\", z)\n",
        "print(\"Shape:\", z.shape)\n",
        "\n",
        "# ----- Flatten to 1D tensor -----\n",
        "# Converts the tensor into a 1D tensor containing all its elements.\n",
        "flat = x.flatten()\n",
        "print(\"\\nFlattened x:\\n\", flat)\n",
        "print(\"Shape:\", flat.shape)\n",
        "\n",
        "# ----- Permute dimensions (swap axes) -----\n",
        "# Rearranges the dimensions of the tensor. For example, (2, 3, 4) becomes (4, 2, 3).\n",
        "perm = x.permute(2, 0, 1)  # from (dim0, dim1, dim2) -> (dim2, dim0, dim1)\n",
        "print(\"\\nPermuted x (2,3,4 -> 4,2,3):\\n\", perm)\n",
        "print(\"Shape:\", perm.shape)\n",
        "\n",
        "# ----- Unsqueeze (covered in next cell) -----\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfohUkK19VCT",
        "outputId": "41618526-49ae-4972-8926-8c74e3203fa1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "Shape: torch.Size([2, 3, 4])\n",
            "\n",
            "Reshaped to (3, 8):\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
            "        [16, 17, 18, 19, 20, 21, 22, 23]])\n",
            "Shape: torch.Size([3, 8])\n",
            "\n",
            "View to (4, 6):\n",
            " tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11],\n",
            "        [12, 13, 14, 15, 16, 17],\n",
            "        [18, 19, 20, 21, 22, 23]])\n",
            "Shape: torch.Size([4, 6])\n",
            "\n",
            "Flattened x:\n",
            " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23])\n",
            "Shape: torch.Size([24])\n",
            "\n",
            "Permuted x (2,3,4 -> 4,2,3):\n",
            " tensor([[[ 0,  4,  8],\n",
            "         [12, 16, 20]],\n",
            "\n",
            "        [[ 1,  5,  9],\n",
            "         [13, 17, 21]],\n",
            "\n",
            "        [[ 2,  6, 10],\n",
            "         [14, 18, 22]],\n",
            "\n",
            "        [[ 3,  7, 11],\n",
            "         [15, 19, 23]]])\n",
            "Shape: torch.Size([4, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ----- Original tensor -----\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(\"Original x:\\n\", x)\n",
        "print(\"Shape:\", x.shape)  # (4,)\n",
        "\n",
        "# ----- UNSQUEEZE: Add a dimension -----\n",
        "# Adds a new dimension of size 1 at the specified position.\n",
        "x_unsq0 = x.unsqueeze(0)  # Add a dimension at index 0, making it (1, 4)\n",
        "print(\"\\nAfter unsqueeze(dim=0):\\n\", x_unsq0)\n",
        "print(\"Shape:\", x_unsq0.shape)  # (1, 4)\n",
        "\n",
        "x_unsq1 = x.unsqueeze(1)  # Add a dimension at index 1, making it (4, 1)\n",
        "print(\"\\nAfter unsqueeze(dim=1):\\n\", x_unsq1)\n",
        "print(\"Shape:\", x_unsq1.shape)  # (4, 1)\n",
        "\n",
        "# ----- SQUEEZE: Remove dimensions of size 1 -----\n",
        "# Removes all dimensions of size 1 from the tensor.\n",
        "x_squeezed0 = x_unsq0.squeeze()  # Removes the singleton dimension from (1, 4), resulting in (4,)\n",
        "print(\"\\nAfter squeeze():\\n\", x_squeezed0)\n",
        "print(\"Shape:\", x_squeezed0.shape)  # (4,)\n",
        "\n",
        "x_squeezed1 = x_unsq1.squeeze()  # Removes the singleton dimension from (4, 1), resulting in (4,)\n",
        "print(\"\\nAfter squeeze() on x_unsq1:\\n\", x_squeezed1)\n",
        "print(\"Shape:\", x_squeezed1.shape)  # (4,)\n",
        "\n",
        "# ----- EXAMPLE WITH 3D TENSOR -----\n",
        "y = torch.randn(2, 1, 3) # Create a 3D tensor with a singleton dimension.\n",
        "print(\"\\nOriginal y:\\n\", y)\n",
        "print(\"Shape:\", y.shape)  # (2, 1, 3)\n",
        "\n",
        "# Unsqueeze at dim=2\n",
        "# Adds a dimension of size 1 at index 2, converting (2, 1, 3) to (2, 1, 1, 3).\n",
        "y_unsq = y.unsqueeze(2)\n",
        "print(\"\\nAfter y.unsqueeze(2):\\n\", y_unsq)\n",
        "print(\"Shape:\", y_unsq.shape)  # (2, 1, 1, 3)\n",
        "\n",
        "# Squeeze to remove all singleton dimensions\n",
        "# Removes the singleton dimensions from (2, 1, 1, 3), resulting in (2, 3).\n",
        "y_squeezed = y_unsq.squeeze()\n",
        "print(\"\\nAfter y_unsq.squeeze():\\n\", y_squeezed)\n",
        "print(\"Shape:\", y_squeezed.shape)  # (2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jHn7xrl-eCg",
        "outputId": "ca104329-f0ee-43d0-9ad7-3523a3314e2e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x:\n",
            " tensor([1, 2, 3, 4])\n",
            "Shape: torch.Size([4])\n",
            "\n",
            "After unsqueeze(dim=0):\n",
            " tensor([[1, 2, 3, 4]])\n",
            "Shape: torch.Size([1, 4])\n",
            "\n",
            "After unsqueeze(dim=1):\n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "Shape: torch.Size([4, 1])\n",
            "\n",
            "After squeeze():\n",
            " tensor([1, 2, 3, 4])\n",
            "Shape: torch.Size([4])\n",
            "\n",
            "After squeeze() on x_unsq1:\n",
            " tensor([1, 2, 3, 4])\n",
            "Shape: torch.Size([4])\n",
            "\n",
            "Original y:\n",
            " tensor([[[ 2.1765, -0.0666, -0.8230]],\n",
            "\n",
            "        [[ 0.2113, -0.8291,  0.7769]]])\n",
            "Shape: torch.Size([2, 1, 3])\n",
            "\n",
            "After y.unsqueeze(2):\n",
            " tensor([[[[ 2.1765, -0.0666, -0.8230]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2113, -0.8291,  0.7769]]]])\n",
            "Shape: torch.Size([2, 1, 1, 3])\n",
            "\n",
            "After y_unsq.squeeze():\n",
            " tensor([[ 2.1765, -0.0666, -0.8230],\n",
            "        [ 0.2113, -0.8291,  0.7769]])\n",
            "Shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy and tesnors"
      ],
      "metadata": {
        "id": "BhTXzqMNAOE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ----- Create a PyTorch tensor -----\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"PyTorch tensor x:\\n\", x)\n",
        "print(\"Type:\", type(x))\n",
        "\n",
        "# ----- Convert PyTorch tensor to NumPy array -----\n",
        "# `numpy()` method converts a CPU tensor to a NumPy array.\n",
        "x_np = x.numpy()\n",
        "print(\"\\nConverted to NumPy array:\\n\", x_np)\n",
        "print(\"Type:\", type(x_np))\n",
        "\n",
        "# ----- Modify NumPy array and see effect on tensor -----\n",
        "# IMPORTANT: When a CPU-based PyTorch tensor is converted to a NumPy array, they often share the same underlying memory.\n",
        "# Modifying one will affect the other.\n",
        "x_np[0, 0] = 100\n",
        "print(\"\\nModified NumPy array x_np:\\n\", x_np)\n",
        "print(\"PyTorch tensor x after modifying NumPy array:\\n\", x)\n",
        "# ✅ Note: They **share memory** if the tensor is on CPU.\n",
        "\n",
        "# ----- Convert NumPy array back to PyTorch tensor -----\n",
        "# `torch.from_numpy()` creates a PyTorch tensor from a NumPy array. This also shares memory.\n",
        "y = torch.from_numpy(x_np)\n",
        "print(\"\\nConverted back to PyTorch tensor y:\\n\", y)\n",
        "print(\"Type:\", type(y))\n",
        "\n",
        "# ----- Create tensor on GPU and convert to NumPy -----\n",
        "if torch.cuda.is_available():\n",
        "    x_gpu = x.to('cuda') # Move tensor x to GPU.\n",
        "    # x_gpu.numpy() would give an error because NumPy cannot directly handle GPU tensors.\n",
        "    x_cpu = x_gpu.cpu()  # First, move the GPU tensor back to CPU.\n",
        "    x_np_gpu = x_cpu.numpy() # Then, convert the CPU tensor to a NumPy array.\n",
        "    print(\"\\nTensor on GPU moved to CPU and converted to NumPy:\\n\", x_np_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJBkOa4H-_YF",
        "outputId": "ca7b1988-cd9f-4a75-84c6-a4e3c49a5b82"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch tensor x:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: <class 'torch.Tensor'>\n",
            "\n",
            "Converted to NumPy array:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Type: <class 'numpy.ndarray'>\n",
            "\n",
            "Modified NumPy array x_np:\n",
            " [[100   2   3]\n",
            " [  4   5   6]]\n",
            "PyTorch tensor x after modifying NumPy array:\n",
            " tensor([[100,   2,   3],\n",
            "        [  4,   5,   6]])\n",
            "\n",
            "Converted back to PyTorch tensor y:\n",
            " tensor([[100,   2,   3],\n",
            "        [  4,   5,   6]])\n",
            "Type: <class 'torch.Tensor'>\n",
            "\n",
            "Tensor on GPU moved to CPU and converted to NumPy:\n",
            " [[100   2   3]\n",
            " [  4   5   6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrQ7mCRGASav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}